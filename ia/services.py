"""
Services pour int√©gration IA (Groq) et g√©n√©ration audio (gTTS).
Gestion d'erreurs robuste avec logging et exceptions typ√©es.
"""
import os
import hashlib
import json
import re
import logging
from pathlib import Path

from django.conf import settings
from groq import Groq
from gtts import gTTS

from api.exceptions import IAServiceError, IAConfigurationError, AudioGenerationError

logger = logging.getLogger(__name__)


def generate_audio(text, lang='fr', slow=False):
    """
    G√©n√®re un fichier audio √† partir d'un texte en utilisant gTTS.
    
    Args:
        text: Texte √† convertir en audio
        lang: Langue (fr, en, etc.)
        slow: Si True, parle plus lentement
    
    Returns:
        str: URL relative du fichier audio (ex: 'audio/abc123.mp3') ou None
    
    Raises:
        AudioGenerationError: En cas d'erreur de g√©n√©ration
    """
    if not text or not text.strip():
        logger.debug("generate_audio: texte vide, retour None")
        return None
    
    # Cr√©er hash du texte pour nom de fichier unique
    text_hash = hashlib.md5(text.encode('utf-8')).hexdigest()
    filename = f"{text_hash}.mp3"
    filepath = settings.AUDIO_STORAGE_PATH / filename
    
    # Si le fichier existe d√©j√†, retourner son URL
    if filepath.exists():
        logger.debug(f"Audio d√©j√† existant: {filename}")
        return f"{settings.MEDIA_URL}audio/{filename}"
    
    try:
        # Nettoyage du texte pour gTTS (Sandy ne doit pas lire le Markdown)
        # Supprimer les ast√©risques (**Bold** -> Bold)
        clean_text = re.sub(r'\*+', '', text)
        # Supprimer les di√®ses (# Titre -> Titre)
        clean_text = re.sub(r'#+\s*', '', clean_text)
        # Tronquer √† 800 caract√®res max pour √©viter les d√©lais gTTS extr√™mes
        if len(clean_text) > 800:
            logger.info(f"Texte trop long ({len(clean_text)}), troncature √† 800 chars pour gTTS")
            clean_text = clean_text[:800] + "..."
        
        # G√©n√©rer audio avec gTTS
        tts = gTTS(text=clean_text, lang=lang, slow=slow)
        tts.save(str(filepath))
        logger.info(f"Audio g√©n√©r√©: {filename}")
        return f"{settings.MEDIA_URL}audio/{filename}"
    except Exception as e:
        logger.error(f"Erreur g√©n√©ration audio: {e}", exc_info=True)
        # Ne pas lever d'exception, retourner None pour permettre un fallback
        return None


def call_groq(prompt, classe=None, contexte=None, max_tokens=2000):
    """
    Appelle l'API Groq pour g√©n√©rer du contenu √©ducatif.
    Utilis√© uniquement pour les niveaux >CP2.
    
    Args:
        prompt: Prompt principal
        classe: Classe de l'√©l√®ve (optionnel, pour contexte)
        contexte: Contexte additionnel (optionnel)
        max_tokens: Limite de tokens
    
    Returns:
        str: R√©ponse g√©n√©r√©e par l'IA
    
    Raises:
        IAConfigurationError: Si GROQ_API_KEY non configur√©e
        IAServiceError: En cas d'erreur API
    """
    if not settings.GROQ_API_KEY:
        logger.error("GROQ_API_KEY non configur√©e")
        raise IAConfigurationError("Cl√© API Groq non configur√©e")
    
    try:
        client = Groq(api_key=settings.GROQ_API_KEY)
        
        # Construire le prompt complet
        system_prompt = """Tu es un tuteur √©ducatif intelligent pour le syst√®me scolaire du Burkina Faso.
Tu adaptes tes explications au niveau de l'√©l√®ve. Sois clair, encourageant et utilise des exemples concrets
du contexte burkinab√® (march√©, village, animaux locaux, etc.)."""
        
        if classe:
            system_prompt += f"\nL'√©l√®ve est en {classe.upper()}."
        
        if contexte:
            system_prompt += f"\nContexte: {contexte}"
        
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": prompt}
        ]
        
        logger.debug(f"Appel Groq - classe: {classe}, tokens max: {max_tokens}")
        
        response = client.chat.completions.create(
            model=settings.GROQ_MODEL,
            messages=messages,
            temperature=0.7,
            max_tokens=max_tokens,
        )
        
        result = response.choices[0].message.content.strip()
        logger.info(f"R√©ponse Groq re√ßue: {len(result)} caract√®res")
        return result
    
    except IAConfigurationError:
        raise
    except Exception as e:
        logger.error(f"Erreur appel Groq: {e}", exc_info=True)
        raise IAServiceError(f"Erreur API IA: {str(e)}")


def call_groq_safe(prompt, classe=None, contexte=None, max_tokens=2000, default=None):
    """
    Version s√ªre de call_groq qui ne l√®ve pas d'exception.
    Utilis√©e pour les cas o√π un fallback est acceptable.
    
    Returns:
        str: R√©ponse IA ou valeur par d√©faut si erreur
    """
    try:
        return call_groq(prompt, classe, contexte, max_tokens)
    except (IAConfigurationError, IAServiceError) as e:
        logger.warning(f"call_groq_safe fallback: {e}")
        return default


def generate_explication_ia(topic, classe, generate_audio_flag=True):
    """
    G√©n√®re une explication personnalis√©e pour un topic en utilisant l'IA.
    Utilis√© uniquement pour >CP2.
    
    Args:
        topic: Instance de Topic
        classe: Classe de l'√©l√®ve
        generate_audio_flag: Si True, g√©n√®re aussi l'audio (lent)
    
    Returns:
        dict: {'explication': str, 'audio_url': str ou None}
    """
    prompt = f"""Explique de mani√®re claire et adapt√©e le th√®me enfantin suivant pour un √©l√®ve de {classe.upper()} au Burkina Faso:

Mati√®re: {topic.matiere.get_nom_display()}
Titre: {topic.titre}
R√©sum√©: {topic.resume}

Structure ton explication de la mani√®re suivante:
1. **Introduction**: Pr√©sente le sujet simplement.
2. **Explication**: D√©taille le concept avec des mots simples.
3. **Exemple concret**: Donne au moins 3 exemples ancr√©s dans le quotidien du Burkina (march√©, village, √©cole, culture locale).
4. **R√©capitulatif**: Les 3 points cl√©s √† retenir.

G√©n√®re une explication d√©taill√©e, encourageante et p√©dagogique."""
    
    explication = call_groq_safe(prompt, classe=classe, default=topic.resume)
    
    if not explication:
        explication = topic.resume
        logger.warning(f"Fallback sur r√©sum√© pour topic {topic.id}")
    
    # G√©n√©rer audio si possible et si demand√©
    audio_url = None
    if generate_audio_flag and explication:
        audio_url = generate_audio(explication, lang='fr')
    
    return {
        'explication': explication,
        'audio_url': audio_url
    }


def generate_exercice_ia(topic, classe, difficulte=1):
    """
    G√©n√®re un exercice personnalis√© pour un topic en utilisant l'IA.
    Utilis√© uniquement pour >CP2.
    
    Args:
        topic: Instance de Topic
        classe: Classe de l'√©l√®ve
        difficulte: Niveau de difficult√© (1-3)
    
    Returns:
        dict: Donn√©es de l'exercice g√©n√©r√©, ou None en cas d'erreur
    """
    prompt = f"""G√©n√®re un exercice √©ducatif adapt√© pour un √©l√®ve de {classe.upper()} au Burkina Faso:

Mati√®re: {topic.matiere.get_nom_display()}
Th√®me: {topic.titre}
Difficult√©: {difficulte}/3

Format de r√©ponse (JSON):
{{
    "question": "Question claire",
    "type": "choix_multiple",
    "options": ["Option 1", "Option 2", "Option 3", "Option 4"],
    "correct_index": 0,
    "feedback_success": "Bravo ! Explique ici pourquoi c'est la bonne r√©ponse.",
    "feedback_fail": "Essaie encore ! Donne une petite piste pour aider."
}}

Utilise des noms et contextes burkinab√® (Ali, Fatou, le march√© de Rood Woko, le village, etc.)."""
    
    response = call_groq_safe(prompt, classe=classe)
    
    if not response:
        return None
    
    return _parse_json_response(response, "exercice")


def generate_exercises_batch_ia(topic, classe, count=5):
    """
    G√©n√®re un lot d'exercices pour un topic en utilisant l'IA.
    
    Args:
        topic: Instance de Topic
        classe: Classe de l'√©l√®ve
        count: Nombre d'exercices √† g√©n√©rer (max 10 recommand√©s par appel)
    
    Returns:
        list: Liste de dicts d'exercices, ou [] en cas d'erreur
    """
    prompt = f"""G√©n√®re un lot de {count} exercices √©ducatifs diff√©rents pour un √©l√®ve de {classe.upper()} au Burkina Faso:

Mati√®re: {topic.matiere.get_nom_display()}
Th√®me: {topic.titre}
R√©sum√© du cours: {topic.resume}

Chaque exercice doit avoir une difficult√© vari√©e (m√©lange de 1, 2 et 3).

Format de r√©ponse (JSON uniquement, une liste d'objets) :
[
    {{
        "question": "Question claire",
        "type": "choix_multiple",
        "options": ["Option 1", "Option 2", "Option 3", "Option 4"],
        "correct_index": 0,
        "feedback_success": "Bravo !...",
        "feedback_fail": "Essaie encore !...",
        "difficulte": 1
    }},
    ...
]

Utilise des noms et contextes burkinab√®."""
    
    response = call_groq_safe(prompt, classe=classe)
    
    if not response:
        return []
    
    data = _parse_json_response(response, "batch_exercises")
    if isinstance(data, list):
        return data
    return [data] if isinstance(data, dict) else []


def chat_tuteur_ia(message, classe, history=None, user_info=None):
    """
    Simule une conversation avec le tuteur intelligent Sandy.
    
    Args:
        message: Message de l'√©l√®ve
        classe: Classe de l'√©l√®ve
        history: Historique de conversation (optionnel)
        user_info: Infos utilisateur {'username': str, 'points': int}
    
    Returns:
        str: R√©ponse de Sandy ou None si erreur
    """
    nom_eleve = user_info.get('username', '√âl√®ve') if user_info else '√âl√®ve'
    points = user_info.get('points', 0) if user_info else 0
    
    # Adaptation du ton selon le niveau
    est_secondaire = classe.lower() not in ['cp1', 'cp2', 'ce1', 'ce2', 'cm1', 'cm2']
    
    pedagogical_context = f"""Tu es Sandy, le Tuteur Intelligent de 'FASO Tuteur'. 
Tu es un renard malin, savant et tr√®s amical ü¶ä.
Ton r√¥le est d'aider les √©l√®ves du Burkina Faso. 
L'√©l√®ve actuel s'appelle {nom_eleve}, il est en {classe.upper()} et a cumul√© {points} points de savoir.

REFORMES ET CONTEXTE ACTUEL (2024-2026) :
- IPEQ : Initiative Pr√©sidentielle pour une √âducation de Qualit√©.
- Anglais introduit d√®s le CP1.
- Port du Faso Dan Fani obligatoire le lundi et jeudi.
- Focus sur l'√©ducation civique et patriotique.
- Langues nationales valoris√©es.

TON STYLE :
- Pour le primaire : Sois tr√®s p√©dagogue, utilise un langage simple, beaucoup d'encouragements et des emojis.
- Pour le secondaire ({'6√®me-Terminale' if est_secondaire else ''}) : Reste amical mais adopte un ton plus mature, pr√©cis et structur√©. Aide-les √† pr√©parer le BEPC ou le Baccalaur√©at si n√©cessaire.
- Utilise toujours des exemples du quotidien burkinab√® (le mil, le Faso Dan Fani, Ouagadougou, Bobo-Dioulasso, les mines d'or, etc.).
- Si le sujet est hors cadre scolaire, ram√®ne gentiment l'√©l√®ve vers ses √©tudes.
- Tu peux utiliser quelques emojis pour rendre la discussion vivante."""
    
    context_with_history = pedagogical_context
    if history:
        context_with_history += "\n\nHistorique r√©cent de la conversation :\n"
        for msg in history[-5:]:  # On garde les 5 derniers √©changes
            role = "√âl√®ve" if msg['role'] == 'user' else "Sandy"
            context_with_history += f"{role}: {msg['content']}\n"
    
    return call_groq_safe(message, classe=classe, contexte=context_with_history)


def generate_essential_questions_ia(matiere_nom, classe, topics_list, count=10):
    """
    G√©n√®re les questions les plus essentielles pour une mati√®re et une classe.
    Chaque question est associ√©e √† l'un des topics fournis.
    
    Args:
        matiere_nom: Nom de la mati√®re
        classe: Classe de l'√©l√®ve
        topics_list: Liste de dicts {'id': int, 'titre': str}
        count: Nombre de questions √† g√©n√©rer
    
    Returns:
        list: Liste de dicts d'exercices avec topic_id
    """
    topics_str = "\n".join([f"- {t['id']}: {t['titre']}" for t in topics_list])
    
    prompt = f"""Tu es un expert p√©dagogique du programme scolaire au Burkina Faso.
Ta mission est de g√©n√©rer les {count} questions les plus ESSENTIELLES pour un √©l√®ve de {classe.upper()} en {matiere_nom.upper()}.
Ces questions doivent couvrir les points fondamentaux que l'√©l√®ve DOIT absolument ma√Ætriser √† la fin de l'ann√©e.

Pour chaque question, choisis le chapitre le plus pertinent parmi la liste suivante :
{topics_str}

Si aucun chapitre ne correspond vraiment, utilise l'ID du chapitre le plus proche ou le premier de la liste.

Format de r√©ponse (JSON uniquement, une liste d'objets) :
[
    {{
        "question": "La question essentielle...",
        "type": "choix_multiple",
        "options": ["R√©ponse A", "R√©ponse B", "R√©ponse C", "R√©ponse D"],
        "correct_index": 0,
        "feedback_success": "Excellent ! C'est une notion de base.",
        "feedback_fail": "Attention, c'est un point essentiel √† revoir.",
        "difficulte": 2,
        "topic_id": 123
    }},
    ...
]
"""
    
    json_str = call_groq_safe(prompt, classe=classe)
    if not json_str:
        return []
    
    data = _parse_json_response(json_str, "essential_questions")
    return data if isinstance(data, list) else []


def _parse_json_response(response, context_name="json"):
    """
    Parse une r√©ponse JSON potentiellement mal format√©e de l'IA.
    
    Args:
        response: R√©ponse texte contenant du JSON
        context_name: Nom du contexte pour les logs
    
    Returns:
        dict ou list: Donn√©es pars√©es, ou None si √©chec
    """
    try:
        # Extraire ce qui ressemble √† du JSON [...] ou {...}
        match = re.search(r'(\[.*\]|\{.*\})', response, re.DOTALL)
        if match:
            json_str = match.group(0)
        else:
            json_str = response
        
        # Supprimer d'√©ventuels commentaires JSON
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        return json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.error(f"Erreur parsing JSON ({context_name}): {e}")
        logger.debug(f"R√©ponse brute (d√©but): {response[:300]}...")
        return None
